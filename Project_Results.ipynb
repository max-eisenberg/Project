{
 "cells": [
  {
   "cell_type": "raw",
   "id": "75a86fe4",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"PIC 16B Project Report\n",
    "\"\n",
    "author: \"\"\n",
    "date: \"\"\n",
    "format:\n",
    "    html:\n",
    "        code-fold: false\n",
    "categories: \n",
    "image: \"strava.jpeg\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a23a1ce",
   "metadata": {},
   "source": [
    "# Github\n",
    "\n",
    "https://github.com/max-eisenberg/Project\n",
    "\n",
    "# Project Description\n",
    "Strava is a popular app used by athletes to track workouts. In our project we give users insight to their current performance and use activity data of users that are outperform the user to give reccomendations on how to improve. The segments feature of strava takes stretches from user activity to compare to other users who also complete that strech in one of their logged activities. Any segment in which a user performs amongst the top ten best is stored in the profile under top tens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934df478",
   "metadata": {},
   "source": [
    "![](flowchart.png)\n",
    "\n",
    "# General Approach\n",
    "\n",
    "This project uses a webscraping approach which required the use of scrapy and selenium. While strava does have an API available to the public, it is severly limited and requires authentification by the user before taking any activity data. Given that our project relies so heavily on a analyzing competitor activities, the API was not of much use to us. This project looks at anyone who outperformed the user in their top tens and use their activity data to help the user improve. With out sraper we first logged into strava, directed to the top tens page, visited all of the top ten segments, got all of the athletes who beat the user in each top ten, then directed to their athelte page to collect all of their activity for the month leading up to their achievement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c688203",
   "metadata": {},
   "source": [
    "# The Proccess\n",
    "\n",
    "## Flow of work\n",
    "\n",
    "With our webscrpaing approach we followed this general flow:\n",
    "- Log in to strava on scrapy\n",
    "- Direct to strava athlete top ten pages \n",
    "- Get links to all top ten segments\n",
    "- Direct to athlete page for all athletes that beat user in that segment\n",
    "    - Specifically we direct to the athelte page which displays all of the activities from the month before that athlete placed in the the top ten segment, ahead of the user.\n",
    "- Log in through selenium\n",
    "- Gather all activiy data from the links for given time period of each athlete, store. \n",
    "\n",
    "## The Scraper\n",
    "With the scraper we first directed to the strava website and logged in and directed to the top ten segments gather all of the athletes ahead of the user and find their activity page corresponding to the month before their acheivement, returning a list of links. This satisfies the project requirement of \"web scraping.\" For our user, the scraper returned a list of 275 athlete pages, each of which would then be analyzed for statistics. \n",
    "\n",
    "Each link that is returned is a specific page from their profile listing the activities for the month prior to their top ten achievement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17fe2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from scrapy.http import FormRequest\n",
    "from scrapy_selenium import SeleniumRequest\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class StravaScraper(scrapy.Spider):\n",
    "    name = \"test\"\n",
    "    athlete = '16735685'\n",
    "    segments =[]\n",
    "    \n",
    "    allowed_domains = ['strava.com']\n",
    "    start_urls = ['https://www.strava.com/login']\n",
    "    \n",
    "    # To define month for athlete url \n",
    "    def __init__(self):\n",
    "        self.date_dict = {'Jan':'01','Feb':'02','Mar':'03','Apr':'04','May':'05','Jun':'06','Jul':'07','Aug':'08',\n",
    "                          'Sep':'09','Oct':'10','Nov':'11','Dec':'12'}\n",
    "        self.month_before = {'Jan':'12','Feb':'01','Mar':'02','Apr':'03','May':'04','Jun':'05','Jul':'06','Aug':'07',\n",
    "                          'Sep':'08','Oct':'09','Nov':'10','Dec':'11'}\n",
    "\n",
    "    #Login to strava\n",
    "    def parse(self, response):\n",
    "        token = response.xpath('//*[@name=\"csrf-token\"]/@content').get()\n",
    "        return FormRequest.from_response(response,\n",
    "                                        formdata={\n",
    "                                            'authenticity_token': token,\n",
    "                                            \n",
    "                                            'email': 'sashaprs@gmail.com',\n",
    "                                            'password': 'PIC16BProject',\n",
    "                                        },\n",
    "                                        #dont_filter=True,\n",
    "                                        #eta={'dont_redirect': True, 'handle_httpstatus_list': [302]},\n",
    "                                        callback=self.parse_after_login)\n",
    "    \n",
    "    #Direct to athlete top ten page\n",
    "    def parse_after_login(self, response):\n",
    "        top_ten_page = f'https://www.strava.com/athletes/{self.athlete}/segments/leader?top_tens=true'\n",
    "        yield scrapy.Request(url=top_ten_page, callback=self.parse_top_tens)\n",
    "\n",
    "    # Yield all top ten segments on page, direct to next page and repeat\n",
    "    def parse_top_tens(self, response):\n",
    "        top_tens = response.css('table.my-segments tbody tr td a::attr(href)').getall()\n",
    "        self.segments.extend(top_tens)\n",
    "        next_page = response.xpath('//li[@class=\"next_page\"]/a[@rel=\"next\"]/@href').get()\n",
    "        if(next_page):\n",
    "            next_page_url = 'https://www.strava.com' + next_page\n",
    "        \n",
    "            yield scrapy.Request(url=next_page_url, callback = self.parse_top_tens)\n",
    "            \n",
    "        for top_ten in self.segments:\n",
    "            #Make sure link is a segment link \n",
    "            if '/segments/' in top_ten:\n",
    "                top_ten = 'https://www.strava.com' + top_ten\n",
    "                yield scrapy.Request(url=top_ten, callback = self.parse_leaderboard)\n",
    "    # get athlete links from segments page\n",
    "    def parse_leaderboard(self, response):\n",
    "        self.counter +=1\n",
    "        self.url_list = [] \n",
    "        athlete_pages = response.css('td.athlete.track-click a::attr(href)').getall()\n",
    "        dates = response.css('a[href^=\"/segment_efforts/\"]::text').getall()\n",
    "        # month before achievement\n",
    "        edited_dates = []\n",
    "        # Record date of achievement in numerical form\n",
    "        for d in dates:\n",
    "            month = self.month_before[d[:3]]\n",
    "            if month == \"12\":\n",
    "                year = int(d[-4:])\n",
    "                year = str(year-1)\n",
    "            else:\n",
    "                year = d[-4:]\n",
    "            edited_dates.append(year+month)\n",
    "\n",
    "        athlete = '16735685'  # Ensure this is a string\n",
    "\n",
    "        athletes_data = {}  \n",
    "        #Stop recording athlete links at user (Only get links for people who beat user)\n",
    "        #Store athlete url and date of achievement together\n",
    "        for i, athlete_url in enumerate(athlete_pages):\n",
    "            if athlete_url.endswith(f'/athletes/{athlete}'):\n",
    "                break\n",
    "            athlete_url = 'https://www.strava.com' + athlete_url\n",
    "            athletes_data[athlete_url] = edited_dates[i]\n",
    "        #Format athlete interval link\n",
    "        for athlete_url, date in athletes_data.items():\n",
    "            interval = str(date)\n",
    "        \n",
    "            year_offset = str(2023 - int(year))\n",
    "            athlete_url = f'{athlete_url}#interval?interval={interval}&interval_type=month&chart_type=miles&year_offset={year_offset}'\n",
    "            yield {'Athlete': athlete_url}\n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc3e05",
   "metadata": {},
   "source": [
    "### Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f64e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Athlete page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.strava.com/athletes/29127886#inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.strava.com/athletes/67093810#inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.strava.com/athletes/282426#interva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.strava.com/athletes/283349#interva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.strava.com/athletes/43161349#inter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Athlete page\n",
       "0  https://www.strava.com/athletes/29127886#inter...\n",
       "1  https://www.strava.com/athletes/67093810#inter...\n",
       "2  https://www.strava.com/athletes/282426#interva...\n",
       "3  https://www.strava.com/athletes/283349#interva...\n",
       "4  https://www.strava.com/athletes/43161349#inter..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "link = pd.read_csv(\"interval_pages.csv\")\n",
    "link.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfd8dd",
   "metadata": {},
   "source": [
    "### Selenium\n",
    "\n",
    "With selenium we first logged into strava and then looped through the list on links from selenium and gather all the activity data from each page. This required us to set up a chrome driver the go into the webpages and find the element we required. We needed to do this to get around the scrpay error we had as the cource code was dynamically rendering, making scrapy requests not useful.\n",
    "\n",
    "With selenium, we directed to the statistics on the activities pages by its xpath, and simillarly to the webscraper saved it all to a csv file for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5112c7d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/selenium/webdriver/common/service.py:72\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m     cmd\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_line_args())\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(cmd, env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m     73\u001b[0m                                     close_fds\u001b[39m=\u001b[39;49mplatform\u001b[39m.\u001b[39;49msystem() \u001b[39m!=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mWindows\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     74\u001b[0m                                     stdout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_file,\n\u001b[1;32m     75\u001b[0m                                     stderr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_file,\n\u001b[1;32m     76\u001b[0m                                     stdin\u001b[39m=\u001b[39;49mPIPE)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[1;32m   1032\u001b[0m                         restore_signals,\n\u001b[1;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[1;32m   1035\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/subprocess.py:1950\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1949\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1950\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1951\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/sasha/Documents/PIC16B/strava_scraper/strava_scraper/spiders/chromedriver'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m urls_list \u001b[39m=\u001b[39m urls[\u001b[39m'\u001b[39m\u001b[39mAthlete page\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m executable_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/Users/sasha/Documents/PIC16B/strava_scraper/strava_scraper/spiders/chromedriver\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(executable_path\u001b[39m=\u001b[39;49mexecutable_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m driver\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mhttps://www.strava.com/login\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m email_field \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element_by_id(\u001b[39m'\u001b[39m\u001b[39memail\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/selenium/webdriver/chrome/webdriver.py:73\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     66\u001b[0m         desired_capabilities\u001b[39m.\u001b[39mupdate(options\u001b[39m.\u001b[39mto_capabilities())\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice \u001b[39m=\u001b[39m Service(\n\u001b[1;32m     69\u001b[0m     executable_path,\n\u001b[1;32m     70\u001b[0m     port\u001b[39m=\u001b[39mport,\n\u001b[1;32m     71\u001b[0m     service_args\u001b[39m=\u001b[39mservice_args,\n\u001b[1;32m     72\u001b[0m     log_path\u001b[39m=\u001b[39mservice_log_path)\n\u001b[0;32m---> 73\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     RemoteWebDriver\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     77\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m     78\u001b[0m         command_executor\u001b[39m=\u001b[39mChromeRemoteConnection(\n\u001b[1;32m     79\u001b[0m             remote_server_addr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mservice_url,\n\u001b[1;32m     80\u001b[0m             keep_alive\u001b[39m=\u001b[39mkeep_alive),\n\u001b[1;32m     81\u001b[0m         desired_capabilities\u001b[39m=\u001b[39mdesired_capabilities)\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/selenium/webdriver/common/service.py:81\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m err\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[39mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m     82\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m executable needs to be in PATH. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m     83\u001b[0m                 os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_error_message)\n\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m     \u001b[39melif\u001b[39;00m err\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mEACCES:\n\u001b[1;32m     86\u001b[0m         \u001b[39mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m     87\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m executable may have wrong permissions. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m     88\u001b[0m                 os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_error_message)\n\u001b[1;32m     89\u001b[0m         )\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "activities = pd.DataFrame()\n",
    "#Testing links\n",
    "test = ['https://www.strava.com/athletes/29127886#interval_type?chart_type=miles&interval_type=month&interval=202012&year_offset=3','https://www.strava.com/athletes/5838343#interval_type?chart_type=miles&interval_type=month&interval=201803&year_offset=5','https://www.strava.com/athletes/28626466#interval_type?chart_type=miles&interval_type=month&interval=202205&year_offset=1']\n",
    "\n",
    "#Actual data,, Set up chrome driver for selenium\n",
    "urls = pd.read_csv('Interval_pages.csv')\n",
    "urls_list = urls['Athlete page']\n",
    "executable_path=\"/Users/sasha/Documents/PIC16B/strava_scraper/strava_scraper/spiders/chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path=executable_path)\n",
    "        \n",
    "#Login to strava\n",
    "driver.get('https://www.strava.com/login')\n",
    "email_field = driver.find_element_by_id('email')\n",
    "email_field.send_keys('sashaprs@gmail.com')\n",
    "password_field = driver.find_element_by_id('password')\n",
    "password_field.send_keys('PIC16BProj')\n",
    "login_button = driver.find_element_by_id('login-button')\n",
    "login_button.click()\n",
    "\n",
    "#Collect activity data\n",
    "for url in urls_list:\n",
    "    temp=[]\n",
    "    activity_stats = [] \n",
    "    names = []\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    #Only get data drom public profiles\n",
    "    #Store name, distance, elevation, time\n",
    "    try:\n",
    "        athlete = driver.find_element(By.CSS_SELECTOR, \"h1.text-title1.athlete-name\").text\n",
    "        name = driver.find_elements(By.XPATH(\"//a[@data-testid='owners-name'\"))\n",
    "        for i in name:\n",
    "            names.append(i.text)\n",
    "        activity_values = driver.find_elements(By.CLASS_NAME, \"------packages-ui-Stat-Stat-module__statValue--phtGK\")\n",
    "        for i in activity_values:\n",
    "            temp.append(i.text)\n",
    "        distance = temp[::3]\n",
    "        elevation = temp[1::3]\n",
    "        time = temp[2::3]\n",
    "        df = pd.DataFrame({'Athlete':athlete,'Name':names,'Distance': distance, 'Elevation': elevation, 'Time': time})\n",
    "        activities = pd.concat([activities, df], axis=0)\n",
    "    except:\n",
    "        pass\n",
    "activities.to_csv('individual_acitivities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b57f654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jae Kim</td>\n",
       "      <td>30.57 mi</td>\n",
       "      <td>2,257 ft</td>\n",
       "      <td>1h 56m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Kim</td>\n",
       "      <td>48.77 mi</td>\n",
       "      <td>2,172 ft</td>\n",
       "      <td>3h 40m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jae Kim</td>\n",
       "      <td>33.18 mi</td>\n",
       "      <td>1,306 ft</td>\n",
       "      <td>2h 11m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jae Kim</td>\n",
       "      <td>31.78 mi</td>\n",
       "      <td>1,150 ft</td>\n",
       "      <td>2h 21m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jae Kim</td>\n",
       "      <td>27.99 mi</td>\n",
       "      <td>1,093 ft</td>\n",
       "      <td>1h 58m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Distance Elevation    Time\n",
       "0  Jae Kim  30.57 mi  2,257 ft  1h 56m\n",
       "1  Jae Kim  48.77 mi  2,172 ft  3h 40m\n",
       "2  Jae Kim  33.18 mi  1,306 ft  2h 11m\n",
       "3  Jae Kim  31.78 mi  1,150 ft  2h 21m\n",
       "4  Jae Kim  27.99 mi  1,093 ft  1h 58m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities = pd.read_csv(\"individual_activities.csv\")\n",
    "activities.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748fb072",
   "metadata": {},
   "source": [
    "## Data Processing and Analysis\n",
    "### Training Reccomendations\n",
    "For the training reccomendations we used the activity data obtained through scrapy and selenium to find the average statistic for each athlete that beat the user. We started with about 2300 rows of activity data which was first cleaned and modified so that we could find the averages. this satisfies the technical component of working with messy or large data.\n",
    "\n",
    "We also used the strava API to get the users acivity data. This required authenification from the user. After obtaining the data we cleaned it and put it in a dataframe. Using the dtae of the activity we were able to organize each activity by week and display their yearly mileage by week to compare to the competitor data. \n",
    "\n",
    "We also used SQL to store the users activity data and created a query function to allow extract all of the activities froma certain day of the week. This can help the user achieve their mileage goals by recognizing the day sin which they tend to ride more so that they can adapt their new training plan. this satisfies the technical component of working with SQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dee1525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Average, people that did better than you on your top 10 segments rode 937.25 miles \n",
      "a month, climbed 69084.92 feet per month, and spent 58.04 hours training. This type \n",
      "of exertion amounts to roughly 234.31 miles and 14.51 hours of training per week. \n",
      "Go get em champ!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('individual_activities.csv')\n",
    "\n",
    "# Getting rid of duplicate activities and non-bike rides\n",
    "df = df.drop_duplicates()\n",
    "df = df[df['Time'].str.endswith('m', 's')]\n",
    "df = df[df['Distance'].str.endswith('mi')]\n",
    "df = df[df['Elevation'].str.endswith('ft')]\n",
    "\n",
    "# Casting Data into integers\n",
    "df['Distance'] = df['Distance'].apply(lambda x: x[:-3] if len(x) > 2 else x)\n",
    "df['Distance'] = df['Distance'].astype(float)\n",
    "\n",
    "df['Elevation'] = df['Elevation'].apply(lambda x: x[:-3] if len(x) > 2 else x)\n",
    "df['Elevation'] = df['Elevation'].str.replace(',', '').astype(int)\n",
    "\n",
    "# Transforming time into minutes, to perform arithmetic\n",
    "hours = np.empty((df.shape[0],1))\n",
    "hrs = []\n",
    "minutes = np.empty((df.shape[0],1))\n",
    "mins = []\n",
    "\n",
    "for i in df['Time']:\n",
    "    if 'h' in i:\n",
    "        loc = i.find('h')\n",
    "        hrs.append(int(i[:loc]))\n",
    "        loc_min = i.find('m')\n",
    "        mins.append(int(i[loc + 2:loc_min]))\n",
    "    else:\n",
    "        loc = i.find('m')\n",
    "        mins.append(int(i[:loc]))\n",
    "\n",
    "hours = np.array(hrs)\n",
    "minutes = np.array(mins)\n",
    "time_minutes = (hours * 60) + minutes\n",
    "\n",
    "df = df.drop('Time', axis=1)\n",
    "df['Time (min)'] = time_minutes\n",
    "\n",
    "# Renaming the columns\n",
    "df = df.rename(columns={'Distance': 'Distance (mi)', 'Elevation': 'Elevation (ft)', 'Name' : 'Athlete Name' })\n",
    "\n",
    "# Calculating the total monthly distances\n",
    "\n",
    "df['Distance (mi)'] = df.groupby('Athlete Name')['Distance (mi)'].transform('sum')\n",
    "df['Elevation (ft)'] = df.groupby('Athlete Name')['Elevation (ft)'].transform('sum')\n",
    "df['Time (min)'] = df.groupby('Athlete Name')['Time (min)'].transform('sum')\n",
    "df = df.rename(columns={'Distance (mi)': 'Monthly Distance (mi)', \n",
    "                        'Elevation (ft)': 'Monthly Elevation (ft)', \n",
    "                        'Time (min)': 'Monthly Time (min)'})\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Putting time into hours\n",
    "df['Monthly Time (min)'] = df['Monthly Time (min)'].apply(lambda x: x/60)\n",
    "df = df.rename(columns={'Monthly Time (min)': 'Monthly Time (hours)'})\n",
    "\n",
    "cleaned_data = df\n",
    "average_distance = cleaned_data['Monthly Distance (mi)'].mean().round(2)\n",
    "average_elevation = cleaned_data['Monthly Elevation (ft)'].mean().round(2)\n",
    "average_time = cleaned_data['Monthly Time (hours)'].mean().round(2)\n",
    "\n",
    "average_weekly_distance = (average_distance/4).round(2)\n",
    "average_weekly_time = (average_time/4).round(2)\n",
    "\n",
    "print(f'On Average, people that did better than you on your top 10 segments rode {average_distance} miles \\na month, climbed {average_elevation} feet per month, and spent {average_time} hours training. This type \\nof exertion amounts to roughly {average_weekly_distance} miles and {average_weekly_time} hours of training per week. \\nGo get em champ!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f42d17",
   "metadata": {},
   "source": [
    "### Arch nemesis\n",
    "\n",
    "For the arch nemesis section we used the list of links we used for selinium to find the users that beat the user most often. Since the link is specific to the timeframe we isolated the athlete ID before find the top three most occuring users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a30724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After looking through your top ten achievements we found all user who beat you in your \n",
      "top ten segments. Consider there people your \"Arch Nemisis.\" We recommend \n",
      "checking out their profile to see how you can improve:  \n",
      " \n",
      " \n",
      "Your greatest arch nemisis beat you 7 times in your current top ten segments. \n",
      "Find their profile here: https://www.strava.com/athletes/14197582\n",
      " \n",
      "Your second greatest arch nemisis beat you 7 times in your current top ten segments.\n",
      "Find their profile here: https://www.strava.com/athletes/5875016\n",
      " \n",
      "Your third greatest arch nemisis beat you 7 times in your current top ten segments. \n",
      "Find their profile here: https://www.strava.com/athletes/497379\n"
     ]
    }
   ],
   "source": [
    "links = pd.read_csv(\"Interval_pages.csv\")\n",
    "#Extract athlete ID\n",
    "links['Athlete ID'] = links['Athlete page'].str.extract(r'/athletes/(\\d+)')\n",
    "links = links.dropna()\n",
    "#Find number of occurrences of each athlete ID\n",
    "from collections import Counter\n",
    "link_counts = Counter(links[\"Athlete ID\"])\n",
    "occurrences_df = pd.DataFrame(list(link_counts.items()), columns=[\"Athlete ID\", \"Occurrences\"])\n",
    "#Order by most occurring\n",
    "occurrences_df = occurrences_df.sort_values(by=\"Occurrences\", ascending=False)\n",
    "occurrences_df = occurrences_df.reset_index(drop=True)\n",
    "\n",
    "#Print top three most occurring athletes with their formatted link\n",
    "print(\"After looking through your top ten achievements we found all user who beat you in your \\ntop ten segments. Consider there people your \\\"Arch Nemisis.\\\" We recommend \\nchecking out their profile to see how you can improve:  \")\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "\n",
    "print(f'Your greatest arch nemisis beat you {occurrences_df.loc[0, \"Occurrences\"]} times in your current top ten segments. \\nFind their profile here: {\"https://www.strava.com/athletes/\"+occurrences_df.loc[0,\"Athlete ID\"]}')\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(f'Your second greatest arch nemisis beat you {occurrences_df.loc[1, \"Occurrences\"]} times in your current top ten segments.\\nFind their profile here: {\"https://www.strava.com/athletes/\"+occurrences_df.loc[1,\"Athlete ID\"]}')\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(f'Your third greatest arch nemisis beat you {occurrences_df.loc[2, \"Occurrences\"]} times in your current top ten segments. \\nFind their profile here: {\"https://www.strava.com/athletes/\"+ occurrences_df.loc[2,\"Athlete ID\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e6e8c0",
   "metadata": {},
   "source": [
    "### API Data\n",
    "\n",
    "The API requires Authenitification from the user so we were able to do this with Max's Profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2179421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Bad Request\",\"errors\":[{\"resource\":\"AuthorizationCode\",\"field\":\"code\",\"code\":\"invalid\"}]}"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X52sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X52sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpage\u001b[39m\u001b[39m'\u001b[39m: page, \u001b[39m'\u001b[39m\u001b[39mper_page\u001b[39m\u001b[39m'\u001b[39m: per_page}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X52sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(activities_url, headers\u001b[39m=\u001b[39;49mheaders, params\u001b[39m=\u001b[39;49mparams)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X52sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     page_activities \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miekevandaelen/Desktop/PIC16B/miekesblog/posts/Report/Project_Results.ipynb#X52sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m page_activities:\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m     \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/urllib3/connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[1;32m   1095\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1096\u001b[0m         (\n\u001b[1;32m   1097\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconn\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1102\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1103\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    612\u001b[0m     server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[1;32m    613\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[1;32m    200\u001b[0m \u001b[39m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/PIC16B-2/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!curl -X POST https://www.strava.com/oauth/token \\\n",
    "        -F client_id=116130 \\\n",
    "        -F client_secret=800ca990d9a63dd2f931139defe2a740fafbbb82 \\\n",
    "        -F code=617a9a395452bcdf79f3e1d53c9e5ff3b29095a6 \\\n",
    "        -F grant_type=authorization_code\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "activities_url = 'https://www.strava.com/api/v3/athlete/activities'\n",
    "\n",
    "#The authorization below comes from generating an authorization code and then running a \n",
    "#command in the terminal to exhange that for an access code.\n",
    "\n",
    "headers = {'Authorization': 'Bearer 2abb7e7b39cad9c2df18773317b6866029945a96'}\n",
    "\n",
    "activities = []\n",
    "\n",
    "page = 1\n",
    "per_page = 100\n",
    "\n",
    "while True:\n",
    "    params = {'page': page, 'per_page': per_page}\n",
    "    response = requests.get(activities_url, headers=headers, params=params)\n",
    "    page_activities = response.json()\n",
    "\n",
    "    if not page_activities:\n",
    "        break\n",
    "    activities.extend(page_activities)\n",
    "    page += 1\n",
    "#Format activity data into a readable dataframe\n",
    "df = pd.DataFrame(activities)\n",
    "\n",
    "keep = ['name', 'distance', 'moving_time', 'total_elevation_gain', \n",
    "                'average_heartrate', 'weighted_average_watts', 'start_date']\n",
    "df = df[keep]\n",
    "df['distance'] = round(df['distance'] * 0.000621371192,2)\n",
    "df['total_elevation_gain'] = round(df['total_elevation_gain'] * 3.28084,2)\n",
    "df['moving_time'] = round(df['moving_time']/3600,2)\n",
    "df['start_date'] = df['start_date'].str.slice(0, 10)\n",
    "\n",
    "df = df.rename(columns={'name' : 'Name', 'distance' : 'Distance (mi)', 'moving_time' : 'Moving Time (hr)', 'total_elevation_gain' : 'Elevation Gain (ft)', \n",
    "                'average_heartrate' : 'Average Heartrate (bpm)', 'weighted_average_watts' : 'Average Power (w)', 'start_date': 'Date'})\n",
    "\n",
    "df\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Add a new column 'Day of the Week' with day of the week as a number (0=Monday, 6=Sunday)\n",
    "df['Day of the Week'] = df['Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62385626",
   "metadata": {},
   "source": [
    "2022 Weekly Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1577b165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('max_data.csv')\n",
    "df['Year']= df[\"Date\"].str[:4]\n",
    "df['Month']= df[\"Date\"].str[5:7]\n",
    "\n",
    "import datetime\n",
    "week = [] \n",
    "#Find numerical week for each activity data\n",
    "for i in df['Date']:\n",
    "    month = int(i[:4])\n",
    "    day = int(i[5:7])\n",
    "    year = int(i[8:])\n",
    "    week.append(datetime.date(month,day,year).strftime(\"%V\"))\n",
    "df['Week']=week\n",
    "\n",
    "#Weekly mileage\n",
    "df_2022 = df[df['Year'] == '2022'].sort_values('Week')\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default=\"iframe\"\n",
    "\n",
    "fig = px.histogram(df_2022, x=\"Week\", y= \"Distance (mi)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cefaae",
   "metadata": {},
   "source": [
    "2022 Monthly Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf33a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Monthly mileage\n",
    "import plotly.express as px\n",
    "# Here we use a column with categorical data\n",
    "fig = px.histogram(df_2022, x=\"Month\", y= \"Distance (mi)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c0451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('max_data.csv')\n",
    "\n",
    "# Make a copy of the original DataFrame 'df'\n",
    "max_df = df.copy()\n",
    "\n",
    "# Define a dictionary to map the old column names to the new shorter names\n",
    "column_name_mapping = {\n",
    "    'Name': 'Name',\n",
    "    'Distance (mi)': 'Distance',\n",
    "    'Moving Time (hr)': 'MovingTime',\n",
    "    'Elevation Gain (ft)': 'ElevationGain',\n",
    "    'Average Heartrate (bpm)': 'AvgHeartrate',\n",
    "    'Average Power (w)': 'AvgPower',\n",
    "    'Date': 'Date',\n",
    "    'Day of the Week':'DayOfWk'\n",
    "}\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Rename the columns in 'max_df' using the mapping\n",
    "max_df = max_df.rename(columns=column_name_mapping)\n",
    "\n",
    "# Now, 'max_df' is a new DataFrame with the desired column names, and 'df' remains unchanged.\n",
    "def query_day_of_week_activities(day):\n",
    "    conn = sqlite3.connect(\"max_data.db\")\n",
    "\n",
    "    cmd = \\\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        m.Name,\n",
    "        m.Distance,\n",
    "        m.MovingTime, \n",
    "        m.ElevationGain,\n",
    "        m.AvgHeartrate, \n",
    "        m.AvgPower,\n",
    "        m.Date,\n",
    "        m.DayOfWk\n",
    "    FROM max_data_condensed m\n",
    "    WHERE m.DayOfWk = ?\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(cmd, conn, params=(day,))\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84900f9e",
   "metadata": {},
   "source": [
    "# Ethical Consideration\n",
    "\n",
    "Our project utilizes public data that is scraped from the Strava webpage. We only collect data that is publicly shared, and only look at statistics such a distance ridden and time spent working out. In order for the data to appear on the Strava webpage initially, the user has to aggree to the terms and conditions, including certain breaches of privacy such as location infortmation. It is also important to not that the final result of our model excludes data associated with specific athlete names, and is a suggestion which is purely based on quantitative analysis. For this reason, there shouldn't be any ethical issues with regard to individuals from which the data is collected. One potential ethical concern with our final result is that the data that is recommended is not entirely accurate. That is, the final prediction is merely a prediction for a certain fitness plan. A particular recommendation that is given could, perhaps, not consider health issues of an individual and consequently result in injury. It would be useful to include a statement to consider this for an individual planning to structure their training on our recommendation system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c5a1cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
